{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TL_n0j55h4BF"
   },
   "outputs": [],
   "source": [
    "# instalattion easyOCR modul\n",
    "!pip install easyocr\n",
    "# connect with Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount( '/content/gdrive' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lv9BvXVAUC7N"
   },
   "outputs": [],
   "source": [
    "# instalattion opencv modul\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656,
     "output_embedded_package_id": "15liSS6e1SoH1Cpr1p8fc5NCC3RLnmMN0"
    },
    "executionInfo": {
     "elapsed": 7373,
     "status": "ok",
     "timestamp": 1630748932405,
     "user": {
      "displayName": "Darko Bosnjak",
      "photoUrl": "",
      "userId": "15697113606420436109"
     },
     "user_tz": -60
    },
    "id": "9WDuX70vHPCp",
    "outputId": "52af99d7-4ed9-4981-caab-5211717fc99d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import cv2 \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "# Detection Licence plate on image\n",
    "class LPDetector:\n",
    "    # init - constructor\n",
    "    def __init__(self, tezine: str, konfig: str, klase: str):\n",
    "        self.net = cv2.dnn.readNet(tezine, konfig)\n",
    "        self.classes = []\n",
    "        with open(klase, 'r') as f:\n",
    "            self.classes = f.read().splitlines()\n",
    "        self.font = cv2.FONT_HERSHEY_PLAIN\n",
    "        self.color = (255, 0, 0)\n",
    "        self.coordinates = None\n",
    "        self.img = None\n",
    "        self.fig_image = None\n",
    "        self.roi_image = None\n",
    "        \n",
    "    # image loading and License plate detection method\n",
    "    def detekcija(self, slike: str):\n",
    "        # Image loading\n",
    "        orig = cv2.imread(slike)\n",
    "        self.img = orig\n",
    "        img = orig.copy()\n",
    "        # Image dimension\n",
    "        height, width, _ = img.shape\n",
    "        blob = cv2.dnn.blobFromImage(img, 1 / 255, (416, 416), (0, 0, 0), swapRB=True, crop=False)\n",
    "        self.net.setInput(blob)\n",
    "        izlaz_sloj = self.net.getUnconnectedOutLayersNames()\n",
    "        izlaz = self.net.forward(izlaz_sloj)\n",
    "        okviri = []\n",
    "        verovatnoca = []\n",
    "        klasa = []\n",
    "        # Object selection and extraction of coordinates and LP dimensions\n",
    "        for izl in izlaz:\n",
    "            for det in izl:\n",
    "                skor = det[5:]\n",
    "                klas = np.argmax(skor) \n",
    "                verov = skor[klas]\n",
    "                if verov > 0.2:\n",
    "                    centar_x = int(det[0] * width)\n",
    "                    centar_y = int(det[1] * height)\n",
    "                    w = int(det[2] * width)\n",
    "                    h = int(det[3] * height)\n",
    "                    x = int(centar_x - w / 2)\n",
    "                    y = int(centar_y - h / 2)\n",
    "\n",
    "                    okviri.append([x, y, w, h])\n",
    "                    verovatnoca.append((float(verov)))\n",
    "                    klasa.append(klas)\n",
    "\n",
    "        indeksi = cv2.dnn.NMSBoxes(okviri, verovatnoca, 0.2, 0.4)\n",
    "\n",
    "        if len(indeksi) > 0:\n",
    "            for i in indeksi.flatten():\n",
    "                x, y, w, h = okviri[i]\n",
    "                label = str(self.classes[klasa[i]])\n",
    "                verov = str(round(verovatnoca[i],2))\n",
    "                # drawing a rectangle around the LP\n",
    "                cv2.rectangle(img, (x,y), (x + w, y + h), self.color, 3)\n",
    "                #print the estimated probability above the LP\n",
    "                #cv2.putText(img, label + ' ' + confidence, (x, y + 10), self.font, 2, (255, 255, 255), 3)\n",
    "        self.fig_image = img\n",
    "        self.coordinates = (x, y, w, h)\n",
    "        return\n",
    "    \n",
    "    # cropping the part of the image that is rectangled\n",
    "    def iseci(self):\n",
    "        x, y, w, h = self.coordinates\n",
    "        roi = self.img[y:y + h, x:x + w]\n",
    "        self.roi_image = roi\n",
    "        return\n",
    "# Forwarding classes of LPDetector weights, configuration and classes after network training\n",
    "lpd = LPDetector(\n",
    "    tezine=\"/content/gdrive/My Drive/yolo_licence_plate/yolov3-train_final.weights\", \n",
    "    konfig=\"/content/gdrive/My Drive/yolo_licence_plate/yolov3-train.cfg\", \n",
    "    klase=\"/content/gdrive/My Drive/yolo_licence_plate/classes.txt\"\n",
    ")\n",
    "    \n",
    "# New LP detection\n",
    "lpd.detekcija(\"/content/0016.JPG\")\n",
    "\n",
    "# Original image with rectangled LP\n",
    "plt.figure(figsize=(24, 24))\n",
    "plt.imshow(cv2.cvtColor(lpd.fig_image, cv2.COLOR_BGR2RGB))\n",
    "#plt.savefig('detected.jpg')\n",
    "plt.show()\n",
    "\n",
    "# Cropped LP and show image\n",
    "lpd.iseci()\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.axis('off')\n",
    "plt.imshow(cv2.cvtColor(lpd.roi_image, cv2.COLOR_BGR2RGB))\n",
    "plt.savefig('croped.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1630745669990,
     "user": {
      "displayName": "Darko Bosnjak",
      "photoUrl": "",
      "userId": "15697113606420436109"
     },
     "user_tz": -60
    },
    "id": "InJEk24LpSv_"
   },
   "outputs": [],
   "source": [
    "\n",
    "import easyocr\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from pylab import rcParams\n",
    "from IPython.display import Image\n",
    "rcParams['figure.figsize']=8,16\n",
    "import cv2\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCPAlB6XpXnz"
   },
   "outputs": [],
   "source": [
    "# language picking-modul easyocr\n",
    "reader = easyocr.Reader(['en'])\n",
    "# loading image\n",
    "img = cv2.imread(\"croped.jpg\")\n",
    "# show image\n",
    "from google.colab.patches import cv2_imshow\n",
    "cv2_imshow(img)\n",
    "# text recognition\n",
    "output = reader.readtext(img)\n",
    "# the coordinates of the upper left and lower right points of the text to eliminate unnecessary parts of the image\n",
    "cord=output[-1][0]\n",
    "x_min,y_min = [min(idx) for idx in zip(*cord)]\n",
    "x_max,y_max = [max(idx) for idx in zip(*cord)]\n",
    "# rectangle around image\n",
    "box = cv2.rectangle(img,(x_min,y_min),(x_max,y_max),(0,0,255),2)\n",
    "cv2_imshow(box)\n",
    "# cropped image with characters\n",
    "roi = box[y_min:y_max, x_min:x_max]\n",
    "cv2_imshow(roi)\n",
    "# transformation color image into gray scale\n",
    "imgray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "# binarization image\n",
    "ret, thresh = cv2.threshold(imgray, 90, 255, 0)\n",
    "# finding individual characters\n",
    "ctrs, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# sorted list of characters\n",
    "sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "c = 0\n",
    "# new folder for images of individual characters\n",
    "!mkdir individual_characters\n",
    "# go through all the rectangled characters, cropp and place in the individual_characters folder\n",
    "for i, ctr in enumerate(sorted_ctrs):\n",
    "    x, y, w, h = cv2.boundingRect(ctr)\n",
    "\n",
    "    roii = roi[y:y + h, x:x + w]\n",
    "    # elimination of contours that do not meet the dimensions of the character\n",
    "    area = w*h\n",
    "    if 500 < area < 4000:\n",
    "        c =c+1\n",
    "        rect = cv2.rectangle(roi, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2_imshow(rect)\n",
    "        num = rect[y:y + h, x:x + w]\n",
    "        num = cv2.cvtColor(num, cv2.COLOR_BGR2GRAY)\n",
    "        ret, num = cv2.threshold(num, 90, 255, 0)\n",
    "        num = cv2.bitwise_not(num)\n",
    "        res = cv2.resize(num,(60,90))\n",
    "        cv2_imshow(res)\n",
    "        cv2.imwrite(\"individual_characters/number\"+str(c)+\".jpg\",res)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-smd2VnKf3V"
   },
   "outputs": [],
   "source": [
    "# individual character recognition\n",
    "\n",
    "# list of character\n",
    "labels = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\", \"B\", \"C\", \"Ć\", \"Č\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"R\", \"S\", \"Š\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"Ž\", \"Đ\"]\n",
    "# CNN model for character recognition\n",
    "prediction_model=load_model(\"/content/gdrive/My Drive/final_model_char.h5\")\n",
    "# path to the folder with individual_characters\n",
    "path = \"/content/individual_characters\"\n",
    "# sorted list\n",
    "filesu = os.listdir(path)\n",
    "files = sorted(filesu)\n",
    "#print(files)\n",
    "predikcija=[]\n",
    "# go through the all images, character clasification and showing text\n",
    "for X in files:\n",
    "  im = \"/content/individual_characters/\"+str(X)\n",
    "  img = cv2.imread(im)\n",
    "  img = np.expand_dims(img, axis=0)\n",
    "  dimensions = img.shape\n",
    "  img = tf.image.resize( img, [60,90] )\n",
    "  Y = prediction_model.predict([img])\n",
    "  #print(Y)\n",
    "  preds_class_prob = np.argmax(Y, axis=1) \n",
    "  class_labels = labels[int(preds_class_prob)]\n",
    "  #print(class_labels)\n",
    "  predikcija.append(class_labels)\n",
    "print(predikcija)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "spxet_tTER1q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMRtwsLN86liJk9AaSfwTDS",
   "collapsed_sections": [],
   "name": "App.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
